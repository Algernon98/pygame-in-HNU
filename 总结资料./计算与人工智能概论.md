# 《计算与人工智能概论》
## 字符串和列表基础
\t 制表符
字符串与数字相乘：字符串重复几次       
3*'un'
字符串和字符串相加：字符串连接起来   
'un'+'ium'
**字符串索引**
下标，第一个字符索引是0
>word = 'Python'
>word[0]
'P'
>word[5]
'n'

索引也可以用负数，这种会从右边开始数：
>word[-1]
>'n'
>word[-2]
>'o'

**字符串切片**
>word[0:2] #左闭右开
>'Py'

切片的索引有默认值；省略开始索引时的默认值为0，省略结束索引时默认为到字符串的结束。

>word[:2]
>word[-2:]

切片步长默认设置为1
>word[::2]#步长设置为2

'''...'''三引号可以跨行输入
>print('''东边儿滴太阳内个亮呦，\
>西边儿下的那个雨，\
>不知道妹妹那个心上人哟，\
>哪时候归来呦。''')

**列表**
>a=eval(input())
>输入：[1,4,9,16,25]
>a = [1,4,9,16,25]

列表也支持索引和切片
最右边是-1
切片也可以赋值

len函数 len()可以获得列表的长度
## 循环
### for循环

```c
for i in range(10):
   print(i)
   i=5
```
**break语句**
break语句，用于跳出最近的for或while循环

**continue语句**
continue语句表示跳过当前的这次循环，直接开始下一次循环

```bash
for num in range(2,10):
   if num%2 == 0:
      print("Found an even number",num)
      continue
   print("Found an odd number",num)
```
## 字符串和列表进阶

### 列表进阶

> **list.append(x)**:在列表的末尾添加一个元素。相当于a[len(a):]=[x]

> **list.insert(i,x)**:在给定的位置插入一个元素。第一个参数是要插入的元素的索引，所以a.insert(0,x)插入列表头部，a.insert(len(a),x)等同于a.append(x)

> **list.remove(x)**:移除列表中第一个值为x的元素。如果没有这样的元素，则抛出ValueError异常。

> **list.pop([i])**:删除列表中给定位置的元素并返回它。如果没有给定位置，a.pop()将会删除并返回列表中的最后一个元素。

> **list.clear()**
> 删除列表中所有的元素

> **list.index(x[,start[,end]])**
> 返回列表中第一个值为x的元素的从零开始的索引。可选参数start和end是切片符号，用于将搜索限制为列表的特定子序列。

> **list.count(x)**
> 返回元素x在列表中出现的次数。

> **list.sort(key=None,reverse=False)**
> 对列表中的元素进行排序。

> **list.reverse()**
> 反转列表中的元素

> **list.copy()**
> 反转列表的一个拷贝。相当于a[:]

### 字符串进阶
字符串实现了所有一般序列的操作，还额外提供了以下列出的一些附加方法。

> **str.capitalize()**
> 返回原字符串的副本，其首个字符大写，其余为小写。
> 

> **str.count(sub[,start,end]])**
> 返回子字符串sub在[start,end]范围内非重叠出现的次数。可选参数start与end会被解读为切片表示法。
> 


> str.find(sub[,start[,end]])
> 返回子字符串sub在s[start:end]切片内被找到的最小索引。可选参数start与end会被解读为切片表示法。如果sub未被找到则返回-1

> str.format(*args,**kwargs)
> 执行字符串格式化操作。

```cpp

>>>"The sum of 1 +2 is {0}".format(1+2)
'The sum of 1+2 is 3'
```
> str.replace(old,new[,count])
> 返回字符串的副本，其中出现的所有字符串old都将被替换为new。如果给出了可选参数count，则只替换前count次出现。
> 
> 


> str.isalnum()
> 如果字符串中所有字符都是字母或数字，则返回True，否则返回False。
> str.isalpha()
> 如果字符串中所有字符都是字母，则返回True，否则返回False。
> str.isdigit()
> 如果字符串中所有字符都是数字，则返回True，否则返回False。
> str.isspace()
> 如果字符串中只有空白字符（空格、制表符、换行符等）则返回True，否则返回False。

### 元组
虽然元组看起来和列表很像，但元组是immutable（不可变的），其序列通常包含不同种类的元素。列表是mutable（可变的），并且列表中的元素一般是同种类型的。

```cpp
t=(12345,54321,'hello!')
```
### 集合
python也包含有集合类型。集合是由不重复元素组成的无序的集。它的基本用法包括成员检测和消除重复元素。集合对象也支持像并集、交集等运算。不支持索引和切片。

## 字典
### 字典的创建
与以连续整数为索引的序列不同，字典是以**关键字**为索引的，关键字可以是任意不可变类型，通常是字符串和数字。
理解字典的最好方式，就是将它看作是一个键：值   对的集合，键必须是唯一的（在一个字典中).

一对花括号可以创建一个空字典：{}
另一种初始化方式是在一对花括号里放置一些以逗号分隔的键值对，而这也是字典输出的方式。

```cpp
tel = {'jack':4098,'sape':4139}
```

通过fromkeys()方法创建字典，初始化操作字典，设置默认值

```cpp
dictname = dict.fromkeys(iterable,value=None)
>>>knowledge={'语文','数学','英语'} #集合
>>>scores=dict.fromkeys(knowledge,60)
>>>print(scores)
{'英语':60,'数学':60,'语文':60,}
```
也可以用del来删除一个键值对

对一个字典执行list(d)将返回包含该字典中所有键的列表，按插入次序排列（如需其他排序，则要使用sorted(d))。要检查字典中是否存在一个特定键，可使用in关键字。

dict（）函数可以直接从键值对序列里创建字典。

> list(d):返回字典d中使用的所有键的列表。
> 

> len(d):返回字典d中的项数。


> d[key]:返回d中以key为键的项。


> d[key] = value：将d[key]设为value


> del d[key]:将d[key]从d中移除。


> key in d :如果d中存在键key则返回True,否则返回False


> key not in d :等价于not key in d


> d.clear():移除字典中的所有元素。


> d.copy():返回原字典的拷贝。

> d.get(key[,default]):如果key存在于字典中则返回key的值，否则返回default
> 
> d.items():返回由字典项((键，值)对)组成的一个新视图（类似列表，里面的元素是键值元组）。


> d.keys():返回由**字典键**组成的一个新视图（类似列表）。

> d.pop(key[,default]):如果 key存在于字典中则将其移除并返回其值，否则返回default。


> d.popitem():从字典中移除并返回一个（键，值）对。

> d.values():返回由**字典值**组成的一个新视图（类似列表）
### 循环的技巧 
当在序列中循环时，用enumerate()函数可以将索引位置和其对应的值同时取出。

```cpp
for i,v in enumerate(['tic','tac','toe']):
    print(i,v)
```
当同时在两个或更多序列中循环时 ，可以用zip()函数将其内元素一一匹配。

当在字典中循环时，用items()方法可将关键字和对应的值同时取出

```cpp
knights={'gallahad':'the pure','robin':'the brave'}
for k,v in knights.items():
    print(k,v)
```
如果要按某个指定顺序循环一个序列，可以用sorted()函数，它可以在不改动 原序列的基础上返回一个新的排好序的序列

```cpp
basket = ['apple','orange','apple','pear','orange','banana']
for  i in sorted(basket):
    print(i)
```
对一个序列使用set()将去除重复的元素。对一个序列使用sorted()加set()则是按排序后顺序循环遍历序列中唯一一种元素的一种惯用方式。

```cpp
basket = ['apple','orange','apple','pear','orange','banana']
for  f in sorted(set(basket)):
    print(f)
```
### 数据类型小结

 

 - Iterable（可迭代类型）：可用于for循环头，常见的由列表、字符串、元组、字典、集合。
 - Sequence（序列类型）：序列是可迭代的，且是可以用整数下标访问的有序排列的一组数，常见的有列表、字符串、元组。其中列表是可变序列(mutable)，字符串和元组的不可变序列（immutable）。

## 函数
关键字def引入一个函数定义。它必须后跟函数名称和带括号的形式参数列表。构成函数体的语句从下一行开始，并且必须缩进。
即使没有return语句的函数也会返回一个值None
### 匿名函数

```cpp
<函数名>=lamda<参数列表>:<代表式>
def<函数名>(<参数列表>):
    return<表达式>
```
lambda函数用于定义简单的、能够在一行内表示的函数，返回一个函数值

### 常用内置函数

> abs(x):返回一个函数的绝对值。

> chr(i):返回 Unicode码位为整数i的字符的字符串格式。

> ord(c）：对表示单个Unicode字符的字符串，返回代表它Unicode码点的整数。
> 
**字符串之间可以直接比较。**
> str(object=''):将object转换为str类型

> len(s):返回对象的长度（元素个数）。实参可以是序列（如string，tuple,list或range等）或集合（如dictionary,set等）。

> list([iterable]):返回一个列表

> sum(iterable,/,start=0):从start开始对iterable的项求和并返回总和。

> pow(base,exp[,mod]):返回base的exp次幂


## 算法设计
**常见的时间复杂度**
|执行次数函数举例|  时间复杂度/说明|
|--|--|
|  217| $o$(1),常数 |
| 4log$n$+12 |$o$(log$n$),对数，log$n$是$log_2n$的简写  |
| 3n+21 |$o$($n$),线性  |
|2$n$+ 3$n$log$n$+15 |$o$($n$log$n$),对数线性，log$n$是$log_2n$的简写  |
| $6n^2+5n+19$ |$o$($n^2$),平方  |
| $2n^3+3n^2+5n+8$ |$o$($n^3$),立方 |
| $7$x$3^n$ |$o$($2^n$),指数 |
### 问题求解计算思维方法
#### 迭代法
迭代法是从某个值开始，不断地利用旧值推导出新值的方法。
#### 穷举法
穷举法也称暴力法，如果在求解问题时，无法找到有效解决问题的方法，可以对所有可能的解进行逐一验证，将符合要求的解找出来。
#### 二分法
二分法通常用来对搜索算法进行优化。
#### 递归
递归是函数调用自身的操作。
递归通常用来将复杂问题一层层地分解为更小的、形式相同的子问题，这种分解会一直进行下去，直到子问题可以直接求解。
#### 深度优先遍历
深度优先遍历（DFS）是一种用于在树形结构或网状结构中进行搜索的有效算法。
**树**是由结点和边组成的不存在任何环的一种数据结构。
一棵树可以被看成由根结点和子树构成，因此，树具有天然的递归结构。
没有结点的树被称为空树。
#### 梯度下降法
**用梯度下降法求一元函数的最值**
一元函数的最值一般通过找函数导数为0的点来求得，即$f^{'}(x)=0$,然而在实际问题中，方程$f^{'}(x)=0$通常不容易求解。梯度下降法不是直接求方程的解，而是通过逐步改变$x$的值，从而找出函数$f(x)$的最小值。


**梯度下降法的基本思想**就是 ：
为了找到函数的最小值处，只要让函数值朝着梯度方向的反方向（下降方向）走一小步，再求出此处的梯度方向，继续往梯度方向的反方向走一小步，如此往复，就能找到函数的最小值。

## 智能感知
### 自然语言处理
依照人们所设定的自然语言语法规则将输入的语句分解为句法结构，再根据一套语义规则把句法结构映射到语义符号结构。
在这套自然语言处理系统中，规则集合是人们预先设计给机器的，是先验的知识。
自然语言处理的任务：

 - 自然语言理解（NLU)
 - 自然语言生成（NLG）
 

### 机器视觉

#### 神经网络

 神经网络的一个典型应用是解决分类问题。
 
 在分类问题中，神经网络一般包含输入层、隐含层和输出层，其中输入层神经元数量由输入向量的维数决定，输出层神经元数量由需要分类的类别数量决定。

输入层不对数据进行处理，仅将输入数据送入下一层进行运算。

在输入层和输出层中间存在若干隐含层，这些隐含层主要用于对数据进行计算和处理。

**前馈神经网络**

![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/d7262ad7e30e4cab3e9e3a8089f8a13b.png#pic_center)
神经网络由大量彼此连接的神经元组成，神经网络的类型由神经元的连接方式决定。
一个常用的神经网络是**多层前馈神经网络**，其中每一层的神经元都与下一层完全互联，并且既没有同层连接也没有跨层连接。
输入层接受外部输入，隐含层和输出层的神经元处理信号，最后输出层的神经元输出结果。
在学习过程中，神经网络根据训练数据调整神经元之间的连接权重和每个功能神经元的阈值。


神经网络的工作过程包括学习期和工作期。
在学习期，每个处理单元通过学习样本修改连接权重。在工作期，每个连接权重是固定的，处理单元的状态会发生变化，最后会达到稳定状态。
##### 卷积神经网络
![在这里插入图片描述](https://img-blog.csdnimg.cn/267534742d124a65b0217c4fca335472.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)
一个传播较为广泛的卷积神经网络是LeNet-5.
主要包括：

 1. 输入层（INPUT层）
 2. 卷积层（C1层，C3层和C5层）
 3. 池化层（S2层和S4层）
 4. 全连接层（F6层）
 5. 输出层（OUTPUT层）

**输入层**可以处理多维数据。卷积神经网络广泛地应用于机器视觉领域，在该领域中的网络的输入数据一般是平面上的像素点所对应的RGB通道，因此一般是三维的。卷积神经网络的学习使用梯度下降法，因此需要对输入数据进行标准化处理。具体而言，对于分布在[0,255]的像素值，需要进行归一化处理，以提升网络的学习效率。

**卷积层**主要对输入数据进行特征提取。一个卷积层包含多个卷积核，每个卷积核都是一个特征提取器。与前馈神经网络中的神经元类似，组成卷积核的每个元素都对应一个权重和一个偏差量。一个卷积核对图像是有一定的卷积范围的，这一范围叫做*感受野*（~~私以为这个翻译并不妥当~~ ）。如果要在不同的尺度上进行特征提取，则需要增加卷积层的数量。

**池化层**主要对卷积层输出的特征图进行特征选择和信息过滤。基本做法是用一个值代替图像的某个区域，这个值可以是最大值（最大池化），也可以是平均值（均值池化）。池化不仅可以降低图像尺寸，在一定程度上也可以使输出值对图像的小幅度平移和旋转不敏感。

**全连接层**主要对之前卷积层和池化层提取到的特征进行非线性组合，从而得到输出信号，它相当于传统前馈神经网络中的隐含层。全连接层的主要任务不是提取特征，而是利用已有的高阶特征达成学习目标。

**输出层**：经过前面一系列的处理后，信号传入输出层，再由逻辑函数或归一化指数函数进行处理，最终输出分类标签，如物体的大小、分类、或每个像素的分类结果。
 

##### 模式识别
对个别事物或现象的识别过程可以被称为模式识别。
模式识别系统通常由数据获取、预处理、特征提取、分类器、分类决策5个基本单元组成。

**特征提取**
常见的特征选择方法有过滤式选择、包裹式选择和嵌入式选择等。

**过滤式选择**是先按照某种规则对数据集进行特征选择，再训练分类器。常见的过滤式选择方法有方差选择法、相关系数法、卡方检验法等。方差选择法认为取值较少的特征对分类没有帮助，它会计算各个特征的方差，根据预先设定的阈值或指定的数量来选取特征。

**包裹式选择**根据学习器的性能来对特征子集进行选择。

**嵌入式选择**结合了以上两者的优点，它将特征选择技术嵌入学习算法，在分类器训练过程中会自动进行特征选择。

## 机器学习
### 监督学习
监督学习是指机器的学习系统通过学习信息之间的组合关系来对来对从未见过的数据进行有效的预测。
回归和分类是监督学习领域中的两个主要任务。
#### 回归
回归是用模型来拟合一组正确的训练数据，以便对未知的一些连续变量进行预测。
#### 分类
分类和回归的主要区别在于：分类用于预测一个离散值或者类别，而不是一系列连续值属性。

### 无监督学习
在无监督学习中，模型只能获取大量的无标记数据，他们需要利用这些无标记数据来进行学习，从而找到这些数据中潜在的组织结构。

无监督学习的主要任务可以分为聚类和降维。

### 半监督学习
同时利用少量标记数据和大量未标记数据进行学习。

## 智能决策
### 基于搜索的最优路径决策
在人工智能领域中，存在着一些非结构化的问题，这类问题通常没有特定的决策模型或者可求解的算法，只能在解空间中通过一步步的试探和摸索来确定可行解。
这样的过程被称为“搜索”，而通过搜索进行求解的问题则被称为“搜索问题”。

著名的八皇后问题便是一个典型的搜索问题。

> 在一个8x8的棋盘上摆放8个棋子，使这8个棋子中的任意2个均不处于棋盘中的同一行、同一列或同一斜线上，一共有多少种可行的摆法？
>

**典型的搜索策略**
![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/9e0f53f93d21363e7118f9ff04119529.png#pic_center)

#### 深度优先搜索（DFS)
深度优先搜索是一种一直向下的盲目搜索方法，搜索从根结点出发，沿一定的方向进行扩展。当无法继续扩展时，回溯到浅层节点，在另一条路径上重新开始扩展。其中，每个结点表示一个状态，子结点后的所有结点被称为该结点的后裔；与该结点位于同一层级的结点被称为兄弟结点。
#### 宽度优先搜索（BFS)
宽度优先搜索又称广度优先搜索，优先扩展层数较低（深度较浅）的结点，仅当某一层的结点全部搜索完毕时，BFS才会进入下一层进行搜索，其具体搜索方法为：
在根结点处生成第一层结点，并在该层中横向进行搜索，检查该层是否存在所需的目标结点；若未找到目标结点，则将第一层的所有结点逐一进行扩展，生成第二层结点，再重复上述步骤，直至发现目标结点。

### 强化学习
强化学习也叫增强学习。
强化学习有4个基本要素，分别是策略、奖励、价值函数以及环境模型。

**策略**是状态到行为的一种映射，它定义了智能体的行为。智能体在给定的状态下所采取的动作取决于策略。

**奖励**是环境对智能体当前行为的一个即时反馈。奖励可以反映智能体学习的任务目标。

**价值函数**是对智能体的序列决策的长期收益的衡量。价值函数与奖励不一样，奖励是环境在智能体每采取一个动作后给予的即时反馈，而价值函数是从一个长远的角度来估计智能体当前行为的好坏的。

**环境模型**是对环境的建模，它定义了不同状态之间的转移概率以及智能体在当前状态下采取某个动作所能获得的奖励。

#### 强化学习与其他机器学习范式的不同
监督学习从带有标记的训练数据中学习预测新的样本。例如，**手写数字识别**就是典型的适合用监督学习解决的问题。

无监督学习从没有标记的训练数据中学习数据的特征，找出数据中潜在的结构并将其分成若干类。无监督学习主要解决预测学习中的聚类问题，例如，从大量无标签的猫猫和狗狗的照片中学习这是两种不同的动物并加以区分。

监督学习和无监督学习本质上都属于预测学习，而强化学习属于决策学习。
强化学习没有标签，它会根据环境的反馈来判断行为的好坏，通过奖励和惩罚来学习最大化行为序列的长期收益。

### 群体智能
**旅行商问题（TSP)** 

 - 蚁群算法
 - 人工蜂群算法
